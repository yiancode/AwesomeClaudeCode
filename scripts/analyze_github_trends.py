#!/usr/bin/env python3
"""
GitHub è¶‹åŠ¿åˆ†æè„šæœ¬ / GitHub Trends Analysis Script

åˆ†æç°æœ‰èµ„æºçš„ Star/Fork è¶‹åŠ¿ï¼Œå‘ç°å¿«é€Ÿå¢é•¿çš„é¡¹ç›®ã€‚
Analyzes Star/Fork trends of existing resources to discover rapidly growing projects.

ç”¨æ³• / Usage:
    python scripts/analyze_github_trends.py [--report] [--update-metadata]
"""

import argparse
import csv
import json
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from urllib.parse import urlparse

import requests
import yaml

# é¡¹ç›®æ ¹ç›®å½• / Project root
PROJECT_ROOT = Path(__file__).parent.parent


def load_config() -> dict:
    """åŠ è½½å‘ç°é…ç½® / Load discovery configuration"""
    config_file = PROJECT_ROOT / "config" / "discovery.yaml"
    with open(config_file, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def load_trends_history() -> dict:
    """åŠ è½½è¶‹åŠ¿å†å²æ•°æ® / Load trends history data"""
    history_file = PROJECT_ROOT / "candidates" / "trends_history.json"
    if history_file.exists():
        with open(history_file, "r", encoding="utf-8") as f:
            return json.load(f)
    return {"_comment": "GitHub èµ„æºè¶‹åŠ¿å†å² / GitHub resource trends history", "repos": {}, "last_updated": None}


def save_trends_history(history: dict):
    """ä¿å­˜è¶‹åŠ¿å†å²æ•°æ® / Save trends history data"""
    history_file = PROJECT_ROOT / "candidates" / "trends_history.json"
    with open(history_file, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)


def load_existing_resources() -> List[dict]:
    """åŠ è½½ç°æœ‰èµ„æº / Load existing resources"""
    resources = []
    csv_file = PROJECT_ROOT / "THE_RESOURCES_TABLE.csv"

    if csv_file.exists():
        with open(csv_file, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            for row in reader:
                resources.append(row)

    return resources


def extract_github_info(url: str) -> Optional[Tuple[str, str]]:
    """ä» URL æå– GitHub owner/repo / Extract GitHub owner/repo from URL"""
    if "github.com" not in url:
        return None

    parts = url.rstrip("/").split("/")
    try:
        github_index = next(i for i, p in enumerate(parts) if "github.com" in p)
        if len(parts) > github_index + 2:
            owner = parts[github_index + 1]
            repo = parts[github_index + 2].replace(".git", "")
            return (owner, repo)
    except (StopIteration, IndexError):
        pass

    return None


def get_repo_stats(owner: str, repo: str, token: Optional[str] = None) -> Optional[dict]:
    """
    è·å–ä»“åº“ç»Ÿè®¡ä¿¡æ¯ / Get repository statistics

    Returns: {stars, forks, watchers, open_issues, pushed_at, ...}
    """
    headers = {"Accept": "application/vnd.github+json", "X-GitHub-Api-Version": "2022-11-28"}
    if token:
        headers["Authorization"] = f"Bearer {token}"

    url = f"https://api.github.com/repos/{owner}/{repo}"

    try:
        response = requests.get(url, headers=headers, timeout=30)
        if response.status_code == 200:
            data = response.json()
            return {
                "stars": data.get("stargazers_count", 0),
                "forks": data.get("forks_count", 0),
                "watchers": data.get("watchers_count", 0),
                "open_issues": data.get("open_issues_count", 0),
                "pushed_at": data.get("pushed_at"),
                "updated_at": data.get("updated_at"),
                "archived": data.get("archived", False),
                "description": data.get("description"),
                "language": data.get("language"),
                "topics": data.get("topics", []),
            }
        elif response.status_code == 404:
            return {"error": "not_found"}
    except requests.exceptions.RequestException as e:
        return {"error": str(e)}

    return None


def get_star_history(owner: str, repo: str, token: Optional[str] = None, days: int = 30) -> List[dict]:
    """
    è·å– Star å†å²ï¼ˆé€šè¿‡ stargazers APIï¼‰
    Get star history (via stargazers API)

    æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªç®€åŒ–å®ç°ï¼ŒGitHub API ä¸ç›´æ¥æä¾›å†å²æ•°æ®
    Note: This is a simplified implementation, GitHub API doesn't provide historical data directly
    """
    # GitHub ä¸æä¾› Star å†å² APIï¼Œè¿™é‡Œåªèƒ½è·å–æœ€è¿‘çš„ stargazers
    # å®Œæ•´çš„ Star å†å²éœ€è¦ä½¿ç”¨ç¬¬ä¸‰æ–¹æœåŠ¡å¦‚ star-history.com
    return []


def calculate_growth_metrics(current_stats: dict, previous_stats: dict, days_elapsed: int) -> dict:
    """
    è®¡ç®—å¢é•¿æŒ‡æ ‡ / Calculate growth metrics

    Returns: {
        star_growth: ç»å¯¹å¢é•¿,
        star_growth_rate: æ—¥å‡å¢é•¿ç‡,
        star_growth_percent: ç™¾åˆ†æ¯”å¢é•¿,
        fork_growth: Fork å¢é•¿,
        activity_score: æ´»è·ƒåº¦è¯„åˆ†
    }
    """
    if not previous_stats or days_elapsed <= 0:
        return {
            "star_growth": 0,
            "star_growth_rate": 0,
            "star_growth_percent": 0,
            "fork_growth": 0,
            "activity_score": 0,
        }

    current_stars = current_stats.get("stars", 0)
    previous_stars = previous_stats.get("stars", 0)
    star_growth = current_stars - previous_stars

    star_growth_rate = star_growth / days_elapsed if days_elapsed > 0 else 0

    if previous_stars > 0:
        star_growth_percent = (star_growth / previous_stars) * 100
    else:
        star_growth_percent = 100 if star_growth > 0 else 0

    fork_growth = current_stats.get("forks", 0) - previous_stats.get("forks", 0)

    # è®¡ç®—æ´»è·ƒåº¦è¯„åˆ†
    activity_score = 0

    # åŸºäº Star å¢é•¿
    if star_growth >= 50:
        activity_score += 40
    elif star_growth >= 20:
        activity_score += 30
    elif star_growth >= 10:
        activity_score += 20
    elif star_growth >= 5:
        activity_score += 10

    # åŸºäºæœ€è¿‘æ›´æ–°
    pushed_at = current_stats.get("pushed_at")
    if pushed_at:
        pushed_date = datetime.fromisoformat(pushed_at.replace("Z", "+00:00"))
        now = datetime.now(pushed_date.tzinfo)
        days_since_push = (now - pushed_date).days

        if days_since_push <= 7:
            activity_score += 30
        elif days_since_push <= 30:
            activity_score += 20
        elif days_since_push <= 90:
            activity_score += 10

    # åŸºäº Fork å¢é•¿
    if fork_growth >= 10:
        activity_score += 20
    elif fork_growth >= 5:
        activity_score += 10

    # åŸºäº issues æ´»è·ƒåº¦
    open_issues = current_stats.get("open_issues", 0)
    if open_issues > 0:
        activity_score += min(10, open_issues)

    return {
        "star_growth": star_growth,
        "star_growth_rate": round(star_growth_rate, 2),
        "star_growth_percent": round(star_growth_percent, 2),
        "fork_growth": fork_growth,
        "activity_score": min(100, activity_score),
    }


def analyze_resource(
    resource: dict, trends_history: dict, token: Optional[str] = None, config: Optional[dict] = None
) -> Optional[dict]:
    """
    åˆ†æå•ä¸ªèµ„æºçš„è¶‹åŠ¿ / Analyze trends for a single resource

    Returns: åˆ†æç»“æœæˆ– None
    """
    url = resource.get("PrimaryLink", "")
    github_info = extract_github_info(url)

    if not github_info:
        return None

    owner, repo = github_info
    full_name = f"{owner}/{repo}"

    # è·å–å½“å‰ç»Ÿè®¡
    current_stats = get_repo_stats(owner, repo, token)

    if not current_stats or current_stats.get("error"):
        return {
            "resource_id": resource.get("ID"),
            "full_name": full_name,
            "status": "error",
            "error": current_stats.get("error", "unknown") if current_stats else "api_error",
        }

    # æ£€æŸ¥æ˜¯å¦å·²å½’æ¡£
    if current_stats.get("archived"):
        return {
            "resource_id": resource.get("ID"),
            "full_name": full_name,
            "status": "archived",
            "current_stats": current_stats,
        }

    # è·å–å†å²æ•°æ®
    repo_history = trends_history.get("repos", {}).get(full_name, {})
    previous_snapshot = repo_history.get("last_snapshot")

    # è®¡ç®—æ—¶é—´é—´éš”
    days_elapsed = 0
    if previous_snapshot:
        last_check = repo_history.get("last_check")
        if last_check:
            last_date = datetime.fromisoformat(last_check)
            days_elapsed = (datetime.now() - last_date).days

    # è®¡ç®—å¢é•¿æŒ‡æ ‡
    growth_metrics = calculate_growth_metrics(current_stats, previous_snapshot, days_elapsed)

    return {
        "resource_id": resource.get("ID"),
        "resource_name": resource.get("DisplayName"),
        "full_name": full_name,
        "url": url,
        "status": "active",
        "current_stats": current_stats,
        "previous_stats": previous_snapshot,
        "days_elapsed": days_elapsed,
        "growth_metrics": growth_metrics,
    }


def update_trends_history(trends_history: dict, analysis_results: List[dict]) -> dict:
    """æ›´æ–°è¶‹åŠ¿å†å² / Update trends history"""
    now = datetime.now().isoformat()

    for result in analysis_results:
        if result.get("status") != "active":
            continue

        full_name = result.get("full_name")
        current_stats = result.get("current_stats", {})

        if full_name not in trends_history["repos"]:
            trends_history["repos"][full_name] = {"snapshots": [], "first_seen": now}

        repo_entry = trends_history["repos"][full_name]

        # æ·»åŠ æ–°å¿«ç…§
        snapshot = {
            "timestamp": now,
            "stars": current_stats.get("stars", 0),
            "forks": current_stats.get("forks", 0),
            "watchers": current_stats.get("watchers", 0),
            "open_issues": current_stats.get("open_issues", 0),
        }

        repo_entry["snapshots"].append(snapshot)

        # åªä¿ç•™æœ€è¿‘ 30 ä¸ªå¿«ç…§
        if len(repo_entry["snapshots"]) > 30:
            repo_entry["snapshots"] = repo_entry["snapshots"][-30:]

        repo_entry["last_snapshot"] = {
            "stars": current_stats.get("stars", 0),
            "forks": current_stats.get("forks", 0),
        }
        repo_entry["last_check"] = now

    trends_history["last_updated"] = now

    return trends_history


def generate_trends_report(analysis_results: List[dict], config: dict) -> str:
    """ç”Ÿæˆè¶‹åŠ¿æŠ¥å‘Š / Generate trends report"""
    trends_config = config.get("trends", {})
    fast_growth_threshold = trends_config.get("fast_growth_threshold_percent", 50)

    report_lines = [
        "# GitHub èµ„æºè¶‹åŠ¿æŠ¥å‘Š / GitHub Resource Trends Report",
        f"\nç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        f"\nåˆ†æèµ„æºæ•°: {len(analysis_results)}",
        "\n---\n",
    ]

    # åˆ†ç±»ç»Ÿè®¡
    active_count = sum(1 for r in analysis_results if r.get("status") == "active")
    archived_count = sum(1 for r in analysis_results if r.get("status") == "archived")
    error_count = sum(1 for r in analysis_results if r.get("status") == "error")

    report_lines.extend(
        [
            "## çŠ¶æ€ç»Ÿè®¡ / Status Statistics",
            f"- æ´»è·ƒ: {active_count}",
            f"- å·²å½’æ¡£: {archived_count}",
            f"- é”™è¯¯: {error_count}",
            "\n---\n",
        ]
    )

    # å¿«é€Ÿå¢é•¿é¡¹ç›®
    active_results = [r for r in analysis_results if r.get("status") == "active"]
    fast_growing = [
        r for r in active_results if r.get("growth_metrics", {}).get("star_growth_percent", 0) >= fast_growth_threshold
    ]
    fast_growing.sort(key=lambda x: x.get("growth_metrics", {}).get("star_growth_percent", 0), reverse=True)

    report_lines.extend([f"## å¿«é€Ÿå¢é•¿é¡¹ç›® / Fast Growing Projects (>{fast_growth_threshold}% å¢é•¿)", ""])

    if fast_growing:
        report_lines.append("| é¡¹ç›® | Stars | å¢é•¿ | å¢é•¿ç‡ | æ´»è·ƒåº¦ |")
        report_lines.append("|------|-------|------|--------|--------|")
        for r in fast_growing[:10]:
            metrics = r.get("growth_metrics", {})
            stats = r.get("current_stats", {})
            report_lines.append(
                f"| [{r.get('resource_name', r.get('full_name'))}]({r.get('url')}) | "
                f"{stats.get('stars', 0)} | "
                f"+{metrics.get('star_growth', 0)} | "
                f"{metrics.get('star_growth_percent', 0)}% | "
                f"{metrics.get('activity_score', 0)} |"
            )
    else:
        report_lines.append("*æ²¡æœ‰å¿«é€Ÿå¢é•¿çš„é¡¹ç›®*")

    report_lines.append("\n---\n")

    # Top æ´»è·ƒé¡¹ç›®
    by_activity = sorted(
        active_results, key=lambda x: x.get("growth_metrics", {}).get("activity_score", 0), reverse=True
    )

    report_lines.extend(["## æœ€æ´»è·ƒé¡¹ç›® / Most Active Projects", ""])

    report_lines.append("| é¡¹ç›® | Stars | æ´»è·ƒåº¦ | æœ€è¿‘æ›´æ–° |")
    report_lines.append("|------|-------|--------|----------|")
    for r in by_activity[:10]:
        metrics = r.get("growth_metrics", {})
        stats = r.get("current_stats", {})
        pushed_at = stats.get("pushed_at", "")
        if pushed_at:
            pushed_at = pushed_at[:10]  # åªæ˜¾ç¤ºæ—¥æœŸéƒ¨åˆ†
        report_lines.append(
            f"| [{r.get('resource_name', r.get('full_name'))}]({r.get('url')}) | "
            f"{stats.get('stars', 0)} | "
            f"{metrics.get('activity_score', 0)} | "
            f"{pushed_at} |"
        )

    report_lines.append("\n---\n")

    # å·²å½’æ¡£é¡¹ç›®è­¦å‘Š
    if archived_count > 0:
        report_lines.extend(["## âš ï¸ å·²å½’æ¡£é¡¹ç›® / Archived Projects", ""])
        for r in analysis_results:
            if r.get("status") == "archived":
                report_lines.append(f"- {r.get('resource_name', r.get('full_name'))}: {r.get('url')}")

    return "\n".join(report_lines)


def main():
    """ä¸»å‡½æ•° / Main function"""
    parser = argparse.ArgumentParser(description="Analyze GitHub trends")
    parser.add_argument("--report", action="store_true", help="Generate trends report")
    parser.add_argument("--update-history", action="store_true", help="Update trends history")
    parser.add_argument("--limit", type=int, default=50, help="Maximum resources to analyze")
    parser.add_argument("--output", type=str, help="Output file for report")
    args = parser.parse_args()

    print("ğŸ“ˆ GitHub è¶‹åŠ¿åˆ†æ / GitHub Trends Analysis")
    print("=" * 50)

    # è·å– GitHub token
    token = os.environ.get("GITHUB_TOKEN")
    if not token:
        print("âš ï¸  æœªè®¾ç½® GITHUB_TOKENï¼ŒAPI é€Ÿç‡é™åˆ¶è¾ƒä½")

    # åŠ è½½é…ç½®å’Œæ•°æ®
    print("\nğŸ“‚ åŠ è½½é…ç½®å’Œæ•°æ®...")
    config = load_config()
    trends_history = load_trends_history()
    existing_resources = load_existing_resources()

    # è¿‡æ»¤å‡º GitHub èµ„æº
    github_resources = []
    for res in existing_resources:
        url = res.get("PrimaryLink", "")
        if "github.com" in url:
            github_resources.append(res)

    github_resources = github_resources[: args.limit]
    print(f"   å°†åˆ†æ {len(github_resources)} ä¸ª GitHub èµ„æº")

    # åˆ†æèµ„æº
    print("\nğŸ”¬ åˆ†æèµ„æºè¶‹åŠ¿...")
    analysis_results = []

    for i, resource in enumerate(github_resources):
        print(f"   [{i + 1}/{len(github_resources)}] {resource.get('DisplayName', 'Unknown')}...", end=" ")

        result = analyze_resource(resource, trends_history, token, config)

        if result:
            analysis_results.append(result)
            status = result.get("status", "unknown")
            if status == "active":
                metrics = result.get("growth_metrics", {})
                print(
                    f"âœ… Stars: {result.get('current_stats', {}).get('stars', 0)}, "
                    f"æ´»è·ƒåº¦: {metrics.get('activity_score', 0)}"
                )
            elif status == "archived":
                print("ğŸ“¦ å·²å½’æ¡£")
            else:
                print(f"âŒ {result.get('error', 'error')}")
        else:
            print("â­ï¸ è·³è¿‡ï¼ˆé GitHubï¼‰")

    # æ›´æ–°å†å²
    if args.update_history:
        print("\nğŸ’¾ æ›´æ–°è¶‹åŠ¿å†å²...")
        trends_history = update_trends_history(trends_history, analysis_results)
        save_trends_history(trends_history)
        print("   âœ… å†å²å·²æ›´æ–°")

    # ç”ŸæˆæŠ¥å‘Š
    if args.report:
        print("\nğŸ“Š ç”Ÿæˆè¶‹åŠ¿æŠ¥å‘Š...")
        report = generate_trends_report(analysis_results, config)

        if args.output:
            output_file = Path(args.output)
            with open(output_file, "w", encoding="utf-8") as f:
                f.write(report)
            print(f"   âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        else:
            print("\n" + report)

    # è¾“å‡ºæ‘˜è¦
    active_count = sum(1 for r in analysis_results if r.get("status") == "active")
    archived_count = sum(1 for r in analysis_results if r.get("status") == "archived")

    print("\nâœ… åˆ†æå®Œæˆï¼")
    print(f"   æ´»è·ƒ: {active_count}, å·²å½’æ¡£: {archived_count}")

    # è¾“å‡ºä¾› GitHub Actions ä½¿ç”¨
    print(f"::set-output name=analyzed_count::{len(analysis_results)}")
    print(f"::set-output name=active_count::{active_count}")
    print(f"::set-output name=archived_count::{archived_count}")

    return 0


if __name__ == "__main__":
    sys.exit(main())
