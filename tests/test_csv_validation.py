"""
CSV æ•°æ®å®Œæ•´æ€§éªŒè¯æµ‹è¯•
CSV Data Integrity Validation Tests

æ ¹æ® CLAUDE.md è¦æ±‚:
- ä½¿ç”¨çœŸå®æ•°æ®ï¼Œä¸ä½¿ç”¨ Mock
- è·Ÿè¸ªæ‰€æœ‰éªŒè¯å¤±è´¥
- æœ‰æ„ä¹‰çš„æ–­è¨€éªŒè¯å…·ä½“é¢„æœŸå€¼
"""

import csv
import sys
from pathlib import Path
from typing import List, Dict, Set

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# CSV æ–‡ä»¶è·¯å¾„
CSV_FILE = PROJECT_ROOT / "THE_RESOURCES_TABLE.csv"

# å¿…å¡«å­—æ®µå®šä¹‰
REQUIRED_FIELDS = [
    "ID",
    "DisplayName",
    "DisplayName_ZH",
    "Category",
    "PrimaryLink",
    "IsActive",
    "Description",
    "Description_ZH",
    "IsPinned",
]

# æ‰€æœ‰å­—æ®µå®šä¹‰ï¼ˆ19ä¸ªå­—æ®µï¼‰
ALL_FIELDS = [
    "ID",
    "DisplayName",
    "DisplayName_ZH",
    "Category",
    "SubCategory",
    "PrimaryLink",
    "SecondaryLink",
    "Author",
    "AuthorProfile",
    "IsActive",
    "DateAdded",
    "LastModified",
    "LastChecked",
    "License",
    "Description",
    "Description_ZH",
    "Tags_ZH",
    "IsPinned",
    "Section",
]


def load_csv_data() -> tuple[List[str], List[Dict[str, str]]]:
    """åŠ è½½ CSV æ•°æ®ã€‚Load CSV data."""
    with open(CSV_FILE, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        fieldnames = reader.fieldnames or []
        rows = list(reader)
    return fieldnames, rows


def test_csv_file_exists():
    """æµ‹è¯• CSV æ–‡ä»¶å­˜åœ¨ã€‚Test CSV file exists."""
    failures = []

    if not CSV_FILE.exists():
        failures.append(f"âŒ CSV æ–‡ä»¶ä¸å­˜åœ¨: {CSV_FILE}")

    return failures


def test_csv_structure():
    """æµ‹è¯• CSV æ–‡ä»¶ç»“æ„å®Œæ•´æ€§ã€‚Test CSV file structure integrity."""
    failures = []

    fieldnames, _ = load_csv_data()

    # éªŒè¯æ‰€æœ‰å­—æ®µéƒ½å­˜åœ¨
    for field in ALL_FIELDS:
        if field not in fieldnames:
            failures.append(f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")

    # éªŒè¯æ²¡æœ‰é¢å¤–å­—æ®µ
    extra_fields = set(fieldnames) - set(ALL_FIELDS)
    if extra_fields:
        failures.append(f"âŒ å‘ç°é¢å¤–å­—æ®µ: {extra_fields}")

    # éªŒè¯å­—æ®µé¡ºåºæ­£ç¡®ï¼ˆå‰19ä¸ªå­—æ®µï¼‰
    expected_order = ALL_FIELDS[: len(fieldnames)]
    if list(fieldnames) != expected_order:
        failures.append("âŒ å­—æ®µé¡ºåºä¸æ­£ç¡®")
        failures.append(f"   æœŸæœ›: {expected_order}")
        failures.append(f"   å®é™…: {list(fieldnames)}")

    return failures


def test_required_fields_present():
    """æµ‹è¯•æ‰€æœ‰èµ„æºåŒ…å«å¿…å¡«å­—æ®µã€‚Test all resources have required fields."""
    failures = []

    _, rows = load_csv_data()

    for i, row in enumerate(rows, start=2):  # ä»ç¬¬2è¡Œå¼€å§‹ï¼ˆç¬¬1è¡Œæ˜¯æ ‡é¢˜ï¼‰
        for field in REQUIRED_FIELDS:
            if not row.get(field) or row[field].strip() == "":
                resource_id = row.get("ID", "unknown")
                failures.append(f"âŒ ç¬¬ {i} è¡Œèµ„æº {resource_id}: ç¼ºå°‘å¿…å¡«å­—æ®µ '{field}'")

    return failures


def test_unique_ids():
    """æµ‹è¯• ID å”¯ä¸€æ€§ã€‚Test ID uniqueness."""
    failures = []

    _, rows = load_csv_data()

    id_counts: Dict[str, int] = {}
    for row in rows:
        resource_id = row.get("ID", "")
        id_counts[resource_id] = id_counts.get(resource_id, 0) + 1

    duplicates = {id_: count for id_, count in id_counts.items() if count > 1}

    if duplicates:
        failures.append(f"âŒ å‘ç° {len(duplicates)} ä¸ªé‡å¤ ID:")
        for id_, count in duplicates.items():
            failures.append(f"   - {id_}: å‡ºç° {count} æ¬¡")

    return failures


def test_id_format():
    """æµ‹è¯• ID æ ¼å¼æ­£ç¡®ï¼ˆprefix-hash8ï¼‰ã€‚Test ID format correctness."""
    failures = []

    _, rows = load_csv_data()

    for i, row in enumerate(rows, start=2):
        resource_id = row.get("ID", "")

        # ID åº”è¯¥æ˜¯ prefix-hash8 æ ¼å¼
        parts = resource_id.split("-")

        if len(parts) != 2:
            failures.append(f"âŒ ç¬¬ {i} è¡Œ: ID '{resource_id}' æ ¼å¼ä¸æ­£ç¡®ï¼ˆåº”ä¸º prefix-hash8ï¼‰")
            continue

        prefix, hash_part = parts

        # Hash éƒ¨åˆ†åº”è¯¥æ˜¯ 8 ä¸ªå­—ç¬¦
        if len(hash_part) != 8:
            failures.append(f"âŒ ç¬¬ {i} è¡Œ: ID '{resource_id}' hash éƒ¨åˆ†é•¿åº¦ä¸æ˜¯ 8 å­—ç¬¦")

        # Hash åº”è¯¥æ˜¯åå…­è¿›åˆ¶
        try:
            int(hash_part, 16)
        except ValueError:
            failures.append(f"âŒ ç¬¬ {i} è¡Œ: ID '{resource_id}' hash éƒ¨åˆ†ä¸æ˜¯æœ‰æ•ˆçš„åå…­è¿›åˆ¶")

    return failures


def test_chinese_encoding():
    """æµ‹è¯•ä¸­æ–‡å­—ç¬¦ç¼–ç æ­£ç¡®æ€§ã€‚Test Chinese character encoding correctness."""
    failures = []

    with open(CSV_FILE, "r", encoding="utf-8") as f:
        content = f.read()

    # éªŒè¯åŒ…å«ä¸­æ–‡å­—ç¬¦
    chinese_keywords = ["å®˜æ–¹", "èµ„æº", "æ•™ç¨‹", "å·¥å…·", "é›†æˆ"]
    found_chinese = any(keyword in content for keyword in chinese_keywords)

    if not found_chinese:
        failures.append(f"âŒ CSV æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ä¸­æ–‡å†…å®¹ï¼ˆæœŸæœ›åŒ…å«: {chinese_keywords}ï¼‰")

    # éªŒè¯ UTF-8 ç¼–ç æ­£ç¡®ï¼ˆé€šè¿‡æˆåŠŸè¯»å–éªŒè¯ï¼‰
    try:
        with open(CSV_FILE, "r", encoding="utf-8") as f:
            f.read()
    except UnicodeDecodeError as e:
        failures.append(f"âŒ UTF-8 ç¼–ç é”™è¯¯: {e}")

    return failures


def test_boolean_fields():
    """æµ‹è¯•å¸ƒå°”å­—æ®µå€¼æ­£ç¡®ã€‚Test boolean field values."""
    failures = []

    _, rows = load_csv_data()

    boolean_fields = ["IsActive", "IsPinned"]
    valid_values = {"TRUE", "FALSE", ""}

    for i, row in enumerate(rows, start=2):
        for field in boolean_fields:
            value = row.get(field, "")
            if value not in valid_values:
                resource_id = row.get("ID", "unknown")
                failures.append(
                    f"âŒ ç¬¬ {i} è¡Œèµ„æº {resource_id}: å­—æ®µ '{field}' å€¼ '{value}' æ— æ•ˆï¼ˆåº”ä¸º TRUE/FALSE/ç©ºï¼‰"
                )

    return failures


def test_url_format():
    """æµ‹è¯• URL æ ¼å¼åŸºæœ¬æ­£ç¡®ã€‚Test URL format basic correctness."""
    failures = []

    _, rows = load_csv_data()

    for i, row in enumerate(rows, start=2):
        resource_id = row.get("ID", "unknown")
        primary_link = row.get("PrimaryLink", "")

        # PrimaryLink æ˜¯å¿…å¡«çš„
        if not primary_link:
            failures.append(f"âŒ ç¬¬ {i} è¡Œèµ„æº {resource_id}: PrimaryLink ä¸ºç©º")
            continue

        # åŸºæœ¬ URL æ ¼å¼æ£€æŸ¥ï¼ˆåº”è¯¥ä»¥ http:// æˆ– https:// å¼€å¤´ï¼‰
        if not (primary_link.startswith("http://") or primary_link.startswith("https://")):
            # å…è®¸æœ¬åœ°æ–‡æ¡£é“¾æ¥ï¼ˆdocs/å¼€å¤´ï¼‰
            if not primary_link.startswith("docs/"):
                failures.append(
                    f"âŒ ç¬¬ {i} è¡Œèµ„æº {resource_id}: PrimaryLink '{primary_link}' "
                    "æ ¼å¼ä¸æ­£ç¡®ï¼ˆåº”ä»¥ http:// æˆ– https:// å¼€å¤´ï¼‰"
                )

    return failures


def test_category_values():
    """æµ‹è¯•åˆ†ç±»å€¼æœ‰æ•ˆã€‚Test category values are valid."""
    failures = []

    # ä» categories.yaml åŠ è½½æœ‰æ•ˆåˆ†ç±»ï¼ˆç®€åŒ–ç‰ˆ - ç›´æ¥ç¡¬ç¼–ç å·²çŸ¥åˆ†ç±»ï¼‰
    valid_categories = {
        "official-resources",
        "skills",
        "workflows",
        "tooling",
        "statusline",
        "hooks",
        "slash-commands",
        "claude-md-files",
        "alternative-clients",
        "mcp-servers",
        "open-source-projects",
        "case-studies",
        "ecosystem",
    }

    _, rows = load_csv_data()

    for i, row in enumerate(rows, start=2):
        resource_id = row.get("ID", "unknown")
        category = row.get("Category", "")

        if category and category not in valid_categories:
            failures.append(f"âŒ ç¬¬ {i} è¡Œèµ„æº {resource_id}: åˆ†ç±» '{category}' æ— æ•ˆ")

    return failures


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•å¹¶æŠ¥å‘Šç»“æœã€‚Run all tests and report results."""
    print("=" * 80)
    print("CSV æ•°æ®éªŒè¯æµ‹è¯• | CSV Data Validation Tests")
    print("=" * 80)
    print()

    all_failures = []
    total_tests = 0

    # å®šä¹‰æ‰€æœ‰æµ‹è¯•
    tests = [
        ("CSV æ–‡ä»¶å­˜åœ¨æ€§", test_csv_file_exists),
        ("CSV ç»“æ„å®Œæ•´æ€§", test_csv_structure),
        ("å¿…å¡«å­—æ®µå®Œæ•´æ€§", test_required_fields_present),
        ("ID å”¯ä¸€æ€§", test_unique_ids),
        ("ID æ ¼å¼æ­£ç¡®æ€§", test_id_format),
        ("ä¸­æ–‡ç¼–ç æ­£ç¡®æ€§", test_chinese_encoding),
        ("å¸ƒå°”å­—æ®µå€¼æ­£ç¡®æ€§", test_boolean_fields),
        ("URL æ ¼å¼æ­£ç¡®æ€§", test_url_format),
        ("åˆ†ç±»å€¼æœ‰æ•ˆæ€§", test_category_values),
    ]

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    for test_name, test_func in tests:
        total_tests += 1
        print(f"ğŸ§ª æµ‹è¯•: {test_name}")
        failures = test_func()

        if failures:
            all_failures.extend(failures)
            print(f"   âŒ å¤±è´¥ ({len(failures)} ä¸ªé—®é¢˜)")
            for failure in failures:
                print(f"      {failure}")
        else:
            print("   âœ… é€šè¿‡")
        print()

    # æœ€ç»ˆç»“æœ
    print("=" * 80)
    if all_failures:
        print(
            f"âŒ éªŒè¯å¤±è´¥ - {len(all_failures)} ä¸ªé—®é¢˜ï¼Œ"
            f"{len([f for f in all_failures if f.startswith('âŒ')])} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œ"
            f"å…± {total_tests} ä¸ªæµ‹è¯•"
        )
        print()
        print("å¤±è´¥è¯¦æƒ…:")
        for failure in all_failures:
            print(f"  {failure}")
        return 1
    else:
        print(f"âœ… éªŒè¯é€šè¿‡ - æ‰€æœ‰ {total_tests} ä¸ªæµ‹è¯•æˆåŠŸ")
        print("CSV æ–‡ä»¶æ•°æ®å®Œæ•´ä¸”æ ¼å¼æ­£ç¡®")
        return 0


if __name__ == "__main__":
    sys.exit(run_all_tests())
